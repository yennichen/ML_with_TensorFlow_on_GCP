{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2b. Machine Learning using tf.estimator </h1>\n",
    "\n",
    "In this notebook, we will create a machine learning model using tf.estimator and evaluate its performance.  The dataset is rather small (7700 samples), so we can do it all in-memory.  We will also simply pass the raw data in as-is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data created in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In CSV, label is the first column, after the features, followed by the key\n",
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "FEATURES = CSV_COLUMNS[1:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[0]\n",
    "\n",
    "df_train = pd.read_csv('./taxi-train.csv', header = None, names = CSV_COLUMNS)\n",
    "df_valid = pd.read_csv('./taxi-valid.csv', header = None, names = CSV_COLUMNS)\n",
    "df_test = pd.read_csv('./taxi-test.csv', header = None, names = CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train and eval input functions to read from Pandas Dataframe </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an appropriate input_fn to read the training data\n",
    "def make_train_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    #ADD CODE HERE\n",
    "      x = df,\n",
    "      y = df[LABEL],\n",
    "      batch_size = 128,\n",
    "      num_epochs = num_epochs,\n",
    "      shuffle = True,\n",
    "      queue_capacity = 1000,\n",
    "      num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an appropriate input_fn to read the validation data\n",
    "def make_eval_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    #ADD CODE HERE\n",
    "      x = df,\n",
    "      y = df[LABEL],\n",
    "      batch_size = 128,\n",
    "      num_epochs = 1,\n",
    "      shuffle = True,\n",
    "      queue_capacity = 1000\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input function for predictions is the same except we don't provide a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an appropriate prediction_input_fn\n",
    "def make_prediction_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    #ADD CODE HERE\n",
    "      x = df,\n",
    "      batch_size = 128,\n",
    "      num_epochs = 1,\n",
    "      shuffle = True,\n",
    "      queue_capacity = 1000\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature columns for estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create feature columns\n",
    "def make_feature_columns():\n",
    "    input_columns = [tf.feature_column.numeric_column(l) for l in FEATURES]\n",
    "    return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression with tf.Estimator framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_task_type': 'worker', '_num_worker_replicas': 1, '_eval_distribute': None, '_protocol': None, '_experimental_distribute': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_train_distribute': None, '_master': '', '_experimental_max_worker_delay_secs': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0b7ad2080>, '_log_step_count_steps': 100, '_global_id_in_cluster': 0, '_service': None, '_is_chief': True, '_save_checkpoints_secs': 600, '_task_id': 0, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_device_fn': None, '_save_summary_steps': 100, '_evaluation_master': ''}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 23611.127, step = 1\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 9 vs previous value: 9. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12 vs previous value: 12. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 15 vs previous value: 15. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 22 vs previous value: 22. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 131.373\n",
      "INFO:tensorflow:loss = 6413.2812, step = 101 (0.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.41\n",
      "INFO:tensorflow:loss = 7964.037, step = 201 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.892\n",
      "INFO:tensorflow:loss = 15510.99, step = 301 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.425\n",
      "INFO:tensorflow:loss = 9181.943, step = 401 (0.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.593\n",
      "INFO:tensorflow:loss = 12152.91, step = 501 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.199\n",
      "INFO:tensorflow:loss = 7777.962, step = 601 (0.540 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 608 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 54.09586.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressor at 0x7fc0b7bbd320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "# TODO: Train a linear regression model\n",
    "model = tf.estimator.LinearRegressor(feature_columns = make_feature_columns(), model_dir = OUTDIR)\n",
    "\n",
    "model.train(make_train_input_fn(df_train,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the validation data (we should defer using the test data to after we have selected a final model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-30T13:08:45Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-30-13:08:47\n",
      "INFO:tensorflow:Saving dict for global step 608: average_loss = 109.53028, global_step = 608, label/mean = 11.666425, loss = 13921.215, prediction/mean = 10.825287\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 608: taxi_trained/model.ckpt-608\n",
      "RMSE on dataset = 10.46567153930664\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, df):\n",
    "  metrics = model.evaluate(input_fn = make_eval_input_fn(df))\n",
    "  print('RMSE on dataset = {}'.format(np.sqrt(metrics['average_loss'])))\n",
    "print_rmse(model, df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nowhere near our benchmark (RMSE of $6 or so on this data), but it serves to demonstrate what TensorFlow code looks like.  Let's use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[10.783358, 10.784651, 10.782515, 10.84396, 10.843606]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Predict from the estimator model we trained using test dataset\n",
    "import itertools\n",
    "prediction = model.predict(make_prediction_input_fn(df_test))\n",
    "\n",
    "print([ pred['predictions'][0] for pred in list(itertools.islice(prediction,5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explains why the RMSE was so high -- the model essentially predicts the same amount for every trip.  Would a more complex model help? Let's try using a deep neural network.  The code to do this is quite straightforward as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_task_type': 'worker', '_num_worker_replicas': 1, '_eval_distribute': None, '_protocol': None, '_experimental_distribute': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_train_distribute': None, '_master': '', '_experimental_max_worker_delay_secs': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc07ea8f908>, '_log_step_count_steps': 100, '_global_id_in_cluster': 0, '_service': None, '_is_chief': True, '_save_checkpoints_secs': 600, '_task_id': 0, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_device_fn': None, '_save_summary_steps': 100, '_evaluation_master': ''}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 11883.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 110.695\n",
      "INFO:tensorflow:loss = 9979.988, step = 101 (0.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.225\n",
      "INFO:tensorflow:loss = 3783.489, step = 201 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.621\n",
      "INFO:tensorflow:loss = 7305.992, step = 301 (0.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.849\n",
      "INFO:tensorflow:loss = 13945.041, step = 401 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.014\n",
      "INFO:tensorflow:loss = 6404.9395, step = 501 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.717\n",
      "INFO:tensorflow:loss = 7346.5244, step = 601 (0.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.486\n",
      "INFO:tensorflow:loss = 10371.602, step = 701 (0.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.795\n",
      "INFO:tensorflow:loss = 8356.5625, step = 801 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.879\n",
      "INFO:tensorflow:loss = 7225.8994, step = 901 (0.637 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 986 vs previous value: 986. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 120.228\n",
      "INFO:tensorflow:loss = 5338.578, step = 1001 (0.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.643\n",
      "INFO:tensorflow:loss = 10892.826, step = 1101 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.901\n",
      "INFO:tensorflow:loss = 19329.352, step = 1201 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.467\n",
      "INFO:tensorflow:loss = 14999.609, step = 1301 (0.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.884\n",
      "INFO:tensorflow:loss = 8883.765, step = 1401 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.627\n",
      "INFO:tensorflow:loss = 15896.657, step = 1501 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.266\n",
      "INFO:tensorflow:loss = 13517.463, step = 1601 (0.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.66\n",
      "INFO:tensorflow:loss = 13447.125, step = 1701 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.65\n",
      "INFO:tensorflow:loss = 14659.666, step = 1801 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.103\n",
      "INFO:tensorflow:loss = 12708.357, step = 1901 (0.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.152\n",
      "INFO:tensorflow:loss = 21150.602, step = 2001 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.957\n",
      "INFO:tensorflow:loss = 11334.32, step = 2101 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.747\n",
      "INFO:tensorflow:loss = 6044.7305, step = 2201 (0.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.025\n",
      "INFO:tensorflow:loss = 9776.61, step = 2301 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.888\n",
      "INFO:tensorflow:loss = 8360.717, step = 2401 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.424\n",
      "INFO:tensorflow:loss = 12288.444, step = 2501 (0.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.491\n",
      "INFO:tensorflow:loss = 22549.34, step = 2601 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.473\n",
      "INFO:tensorflow:loss = 13924.773, step = 2701 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.396\n",
      "INFO:tensorflow:loss = 7017.1406, step = 2801 (0.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.943\n",
      "INFO:tensorflow:loss = 6801.6553, step = 2901 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.008\n",
      "INFO:tensorflow:loss = 14280.86, step = 3001 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.124\n",
      "INFO:tensorflow:loss = 8675.164, step = 3101 (0.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.974\n",
      "INFO:tensorflow:loss = 13010.76, step = 3201 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.708\n",
      "INFO:tensorflow:loss = 10643.982, step = 3301 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.197\n",
      "INFO:tensorflow:loss = 7408.8364, step = 3401 (0.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.018\n",
      "INFO:tensorflow:loss = 12966.79, step = 3501 (0.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.239\n",
      "INFO:tensorflow:loss = 13599.661, step = 3601 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.928\n",
      "INFO:tensorflow:loss = 7570.3037, step = 3701 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.49\n",
      "INFO:tensorflow:loss = 16159.361, step = 3801 (0.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.838\n",
      "INFO:tensorflow:loss = 3017.018, step = 3901 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.246\n",
      "INFO:tensorflow:loss = 10412.898, step = 4001 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.588\n",
      "INFO:tensorflow:loss = 6269.4756, step = 4101 (0.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.943\n",
      "INFO:tensorflow:loss = 11770.41, step = 4201 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.041\n",
      "INFO:tensorflow:loss = 20032.459, step = 4301 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.828\n",
      "INFO:tensorflow:loss = 7580.113, step = 4401 (0.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.599\n",
      "INFO:tensorflow:loss = 11739.52, step = 4501 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.34\n",
      "INFO:tensorflow:loss = 8578.104, step = 4601 (0.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.12\n",
      "INFO:tensorflow:loss = 9965.992, step = 4701 (0.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.473\n",
      "INFO:tensorflow:loss = 8788.545, step = 4801 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.984\n",
      "INFO:tensorflow:loss = 8568.822, step = 4901 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.216\n",
      "INFO:tensorflow:loss = 5548.7114, step = 5001 (0.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.343\n",
      "INFO:tensorflow:loss = 6758.767, step = 5101 (0.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.452\n",
      "INFO:tensorflow:loss = 10485.051, step = 5201 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.615\n",
      "INFO:tensorflow:loss = 13742.609, step = 5301 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.46\n",
      "INFO:tensorflow:loss = 14267.514, step = 5401 (0.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.585\n",
      "INFO:tensorflow:loss = 11477.884, step = 5501 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.604\n",
      "INFO:tensorflow:loss = 3990.4138, step = 5601 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.303\n",
      "INFO:tensorflow:loss = 12085.722, step = 5701 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.408\n",
      "INFO:tensorflow:loss = 8424.783, step = 5801 (0.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.689\n",
      "INFO:tensorflow:loss = 10932.859, step = 5901 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.444\n",
      "INFO:tensorflow:loss = 12639.865, step = 6001 (0.615 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6071 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1757.4987.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x7fc07ea8f6d8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Copy your LinearRegressor estimator and replace with DNNRegressor. Remember to add a list of hidden units i.e. [32, 8, 2]\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "model = tf.estimator.DNNRegressor(hidden_units = [32,8,2], feature_columns = make_feature_columns(), model_dir = OUTDIR)\n",
    "\n",
    "model.train(make_train_input_fn(df_train,100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-30T13:22:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-30-13:22:05\n",
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 109.45522, global_step = 6071, label/mean = 11.666429, loss = 13911.676, prediction/mean = 10.869387\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6071: taxi_trained/model.ckpt-6071\n",
      "RMSE on dataset = 10.462084770202637\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model, df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not beating our benchmark with either model ... what's up?  Well, we may be using TensorFlow for Machine Learning, but we are not yet using it well.  That's what the rest of this course is about!\n",
    "\n",
    "But, for the record, let's say we had to choose between the two models. We'd choose the one with the lower validation error. Finally, we'd measure the RMSE on the test data with this chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Benchmark dataset </h2>\n",
    "\n",
    "Let's do this on the benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1 = train 2 = valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT\n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  EXTRACT(DAYOFWEEK FROM pickup_datetime) * 1.0 AS dayofweek,\n",
    "  EXTRACT(HOUR FROM pickup_datetime) * 1.0 AS hourofday,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count * 1.0 AS passengers,\n",
    "  CONCAT(CAST(pickup_datetime AS STRING), CAST(pickup_longitude AS STRING), CAST(pickup_latitude AS STRING), CAST(dropoff_latitude AS STRING), CAST(dropoff_longitude AS STRING)) AS key\n",
    "FROM\n",
    "  `nyc-tlc.yellow.trips`\n",
    "WHERE\n",
    "  trip_distance > 0\n",
    "  AND fare_amount >= 2.5\n",
    "  AND pickup_longitude > -78\n",
    "  AND pickup_longitude < -70\n",
    "  AND dropoff_longitude > -78\n",
    "  AND dropoff_longitude < -70\n",
    "  AND pickup_latitude > 37\n",
    "  AND pickup_latitude < 45\n",
    "  AND dropoff_latitude > 37\n",
    "  AND dropoff_latitude < 45\n",
    "  AND passenger_count > 0\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # Training\n",
    "      query = \"{0} AND MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 4) < 2\".format(base_query)\n",
    "    else:\n",
    "      # Validation\n",
    "      query = \"{0} AND MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), 4) = {1}\".format(base_query, phase)\n",
    "  else:\n",
    "    query = \"{0} AND MOD(ABS(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING))), {1}) = {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "query = create_query(2, 100000)\n",
    "df = bigquery.Client().query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-30T13:24:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-30-13:24:35\n",
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 89.05051, global_step = 6071, label/mean = 11.232336, loss = 11394.086, prediction/mean = 10.869664\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6071: taxi_trained/model.ckpt-6071\n",
      "RMSE on dataset = 9.436657905578613\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE on benchmark dataset is <b>9.41</b> (your results will vary because of random seeds).\n",
    "\n",
    "This is not only way more than our original benchmark of 6.00, but it doesn't even beat our distance-based rule's RMSE of 8.02.\n",
    "\n",
    "Fear not -- you have learned how to write a TensorFlow model, but not to do all the things that you will have to do to your ML model performant. We will do this in the next chapters. In this chapter though, we will get our TensorFlow model ready for these improvements.\n",
    "\n",
    "In a software sense, the rest of the labs in this chapter will be about refactoring the code so that we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Create a neural network that is capable of finding the volume of a cylinder given the radius of its base (r) and its height (h). Assume that the radius and height of the cylinder are both in the range 0.5 to 2.0. Simulate the necessary training dataset.\n",
    "<p>\n",
    "Hint (highlight to see):\n",
    "<p style='color:white'>\n",
    "The input features will be r and h and the label will be $\\pi r^2 h$\n",
    "Create random values for r and h and compute V.\n",
    "Your dataset will consist of r, h and V.\n",
    "Then, use a DNN regressor.\n",
    "Make sure to generate enough data.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
